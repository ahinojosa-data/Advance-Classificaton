{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classification - Ensemble Methods - Exercises with Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 \n",
    "##### Import the required packages to perform random forest and ensemble methods.\n",
    "##### Set the working directory to data directory.\n",
    "\n",
    "##### Print the working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "import pickle\n",
    "\n",
    "# Model set up and tuning packages from scikit-learn.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scikit-learn package for data preprocessing.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Scikit-learn packages for evaluating model performance.\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Random forest and boosting packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Set `home_dir` to the root directory of your computer.\n",
    "home_dir = Path.home()\n",
    "\n",
    "# Set `main_dir` to the location of your `advanced-classification` folder.\n",
    "main_dir = home_dir / \"Desktop\" / \"advanced-classification\"\n",
    "\n",
    "# Make `data_dir` from the `main_dir` and remainder of the path to data directory.\n",
    "data_dir = main_dir / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory.\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Check the working directory.\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Load the dataset `bank_marketing.csv` and save it to `bank_marketing`.\n",
    "##### Print the first few rows of `bank_marketing`.\n",
    "##### Print the frequecy of the target variable `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T14:51:41.501693Z",
     "start_time": "2020-06-22T14:51:41.453678Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bank_marketing = pd.read_csv(\"bank_marketing.csv\")\n",
    "bank_marketing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_marketing['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Check for NA's `bank_marketing` and print the count of NA's in each column. If the missing value is from a integer type column, fill it with the mean value of the column.\n",
    "##### Now, print the count of NA's in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_marketing.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing = bank_marketing.fillna(bank_marketing.mean()['pdays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_marketing.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Print the datatypes of all the columns and convert the categorical columns to dummy variables.\n",
    "##### The datatype of target variable needs to be binary. Check for the datatype of the target variable and convert it to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing = pd.get_dummies(bank_marketing, columns=['job', 'marital','education','default','housing','loan','contact','month','day_of_week','poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing[\"y\"] = np.where(bank_marketing[\"y\"] == \"yes\", True, False)\n",
    "\n",
    "# Check class again.\n",
    "print(bank_marketing.y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Select the predictors by dropping variable `y` and save the result to a dataframe `X_ex`.\n",
    "##### Save the target variable `y` column to `y_ex` variable.\n",
    "##### Set seed as 1.\n",
    "##### Split the data into train and test sets and save respective variables to `X_train_ex`, `X_test_ex`, `y_train_ex`, `y_test_ex`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the predictors and target.\n",
    "X_ex = bank_marketing.drop(['y'], axis = 1)\n",
    "y_ex = np.array(bank_marketing['y'])\n",
    "\n",
    "# Set the seed to 1.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split into training and test sets.\n",
    "X_train_ex, X_test_ex, y_train_ex, y_test_ex = train_test_split(X_ex, y_ex, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Create a random forest classifier and save it to `forest_ex` variable.\n",
    "##### Set random state to 1, number of estimators to 100 and `gini` as the criterion in the model.\n",
    "##### Fit the classifier to our training data.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_ex = RandomForestClassifier(criterion = 'gini', n_estimators = 100, \n",
    "                                random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_ex.fit(X_train_ex, y_train_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Predict on the test data and print the first 5 predictions on the test data.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data.\n",
    "y_predict_forest_ex = forest_ex.predict(X_test_ex)\n",
    "\n",
    "# Look at the first few predictions.\n",
    "print(y_predict_forest_ex[0:5, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Print the confusion matrix and save it as `conf_matrix_forest_ex`.\n",
    "##### Print the accuracy score as `accuracy_forest_ex`.\n",
    "##### Compute the accuracy on the training data.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_forest_ex = metrics.confusion_matrix(y_test_ex, y_predict_forest_ex)\n",
    "print(conf_matrix_forest_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_forest_ex = metrics.accuracy_score(y_test_ex, y_predict_forest_ex)\n",
    "print(\"Accuracy for random forest on test data: \", accuracy_forest_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy using training data.\n",
    "acc_train_forest_ex = forest_ex.score(X_train_ex, y_train_ex)\n",
    "\n",
    "print (\"Train Accuracy:\", acc_train_forest_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Load the pickle `ex_model_final_logistic.sav` and save it as `ex_model_final_tree`.\n",
    "##### Append the test accuracy `accuracy_forest_ex` to the dataframe `ex_model_final_tree`.\n",
    "##### Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_model_final_tree = pickle.load(open(\"ex_model_final_logistic.sav\",\"rb\"))\n",
    "\n",
    "# Create a dictionary with accuracy values for our knn model with k = 5.\n",
    "ex_model_final_tree = ex_model_final_tree.append({'metrics': \"accuracy\",\n",
    "               'values':round(accuracy_forest_ex,4),\n",
    "                'model':'random_forest'},\n",
    "                ignore_index = True)\n",
    "                           \n",
    "print(ex_model_final_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Print the feature importance graph and print the top 10 important features in our random forest model.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_features = bank_marketing.drop('y', axis = 1)\n",
    "\n",
    "features_ex = bank_marketing_features.columns\n",
    "importances_ex = forest_ex.feature_importances_\n",
    "indices_ex = np.argsort(importances_ex)[::-1]\n",
    "top_indices_ex = indices_ex[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance of Bank marketing dataset')\n",
    "plt.barh(range(len(top_indices_ex)), importances_ex[top_indices_ex], color = 'b', align = 'center')\n",
    "labels = features_ex[top_indices_ex]\n",
    "labels = [ '\\n'.join(wrap(l,13)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices_ex)), labels)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "#### Task 1\n",
    "\n",
    "##### Create a gradient boosting classifier as `gbm_ex` with number of estimators set to 100, learning rate set to 1, max depth set to 1, and random state set to 1.\n",
    "##### Fit the model to our training data.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters we will be using for our gradient boosting classifier.\n",
    "gbm_ex = GradientBoostingClassifier(n_estimators = 100, \n",
    "                                    learning_rate = 1, \n",
    "                                    max_depth = 1,  \n",
    "                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the saved model to your training data.\n",
    "gbm_ex.fit(X_train_ex, y_train_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Predict on the test data using our gbm classifier.\n",
    "##### Print the first 5 predicted values.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data.\n",
    "predicted_values_gbm_ex = gbm_ex.predict(X_test_ex)\n",
    "print(predicted_values_gbm_ex[0:5,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Print the confusion matrix and accuracy score on the test data.\n",
    "##### Print the training accuracy of gbm model.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_boosting_ex = metrics.confusion_matrix(y_test_ex, predicted_values_gbm_ex)\n",
    "print(conf_matrix_boosting_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test model accuracy score.\n",
    "accuracy_gbm_ex = metrics.accuracy_score(y_test_ex, predicted_values_gbm_ex)\n",
    "print('Accuracy of gbm on test data: ', accuracy_gbm_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy using training data.\n",
    "train_accuracy_gbm_ex = gbm_ex.score(X_train_ex, y_train_ex)\n",
    "\n",
    "print (\"Train Accuracy:\", train_accuracy_gbm_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Print the feature importance graph and print top 10 important predictors.\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_features = bank_marketing.drop('y', axis = 1)\n",
    "\n",
    "features_ex = bank_marketing_features.columns\n",
    "importances_ex = gbm_ex.feature_importances_\n",
    "indices_ex = np.argsort(importances_ex)[::-1]\n",
    "top_indices_ex = indices_ex[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance of Bank marketing dataset')\n",
    "plt.barh(range(len(top_indices_ex)), importances_ex[top_indices_ex], color = 'b', align = 'center')\n",
    "labels = features_ex[top_indices_ex]\n",
    "labels = [ '\\n'.join(wrap(l,13)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices_ex)), labels)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5 \n",
    "\n",
    "##### Append the test accuracy `accuracy_gbm_ex` to the dataframe `ex_model_final_tree`.\n",
    "##### Print the results.\n",
    "##### Remember to pickle the dataframe as `ex_model_tree.sav` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the gbm model to our dataframe.\n",
    "ex_model_final_tree = ex_model_final_tree.append({'metrics' : \"accuracy\" , \n",
    "                                                'values' : round(accuracy_gbm_ex,4),\n",
    "                                                'model':'gbm' } , \n",
    "                                                ignore_index = True)\n",
    "print(ex_model_final_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ex_model_final_tree, open(\"ex_model_final_tree.sav\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
