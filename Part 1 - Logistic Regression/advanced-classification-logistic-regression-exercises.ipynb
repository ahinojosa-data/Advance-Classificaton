{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classification - Logistic Regression - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 \n",
    "##### Import the required packages to perform logistic regression.\n",
    "##### Set the working directory to data directory.\n",
    "##### Print the working directory.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Load the dataset `bank_marketing.csv` and save it to `bank_marketing`.\n",
    "##### Print the first few rows of `bank_marketing`.\n",
    "##### Print the frequecy of the target variable `y`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Check for NA's `bank_marketing` and print the count of NA's in each column. If the missing value is from a integer type column, fill it with the mean value of the column.\n",
    "##### Now, print the count of NA's in each column.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Check the data types of the columns.\n",
    "##### Subset the dataset with only numeric columns and target variable and name it `bank_marketing_subset` .\n",
    "##### Once you ensure that all variables are numeric, transform the target variable `y` to boolean and check the data type again.\n",
    "##### Print the first few rows of `bank_marketing_subset_ex`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Select the predictors by dropping variable `y` and save the result to a dataframe `X_ex`.\n",
    "##### Save the target variable `y` column to `y_ex` variable.\n",
    "##### Set seed as 1.\n",
    "##### Split the data into train and test sets and save respective variables to `X_train_ex`, `X_test_ex`, `y_train_ex`, `y_test_ex`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Instantiate the logistic regression model and save it to `ex_logistic_regression_model`. Print it.\n",
    "##### Fit the model with our training sets `X_train_ex` and `y_train_ex`.\n",
    "##### Note: If you encounter any warning, use the code below to set up the logistic regression model.\n",
    "##### logistic_regression_model_ex = linear_model.LogisticRegression(solver='lbfgs')\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Now use the trained model to predict on our test set `X_test_ex`. Save as `predicted_values_ex`.\n",
    "##### Print the vector of predictions obtained.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Create a confusion matrix using the `metrics.confusion_matrix()` function.\n",
    "##### Save as `conf_matrix_ex` and print.\n",
    "##### What can you determine by looking at the confusion matrix?\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Calculate the accuracy of our model by comparing our predicted values against our test set `y_test_ex`.\n",
    "##### Save as `test_accuracy_ex` and print.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Create a list named `target_names` with the class names, `no` and `yes`.\n",
    "##### Create a report `class_report_ex` using our test values `y_test_ex` and predicted values `predicted_values_ex` with the following columns:\n",
    "- precision\n",
    "- recall\n",
    "- f1-score\n",
    "- target_names\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Create a dataframe to store the accuracy and the model used. Name the dataframe as `model_final_ex`.\n",
    "##### Pickle the dataframe to the file `model_final_ex`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Get the probabilities of predicted values `X_test_ex` and save as `test_probabilities_ex`.\n",
    "##### Then, calculate the probabilities of test predictions only.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Derive the `fpr`, `tpr`, and the `threshold` using our test set and predictions.\n",
    "##### Then, calculate the `auc` using the derived `fpr` and `tpr`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Plot ROC curve plot using the values derived above.\n",
    "\n",
    "##### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Use the dataframe `bank_marketing` and print the datatypes of all the columns. Convert all the categorical columns to dummy variables.\n",
    "##### The datatype of target variable needs to be binary. Check for the datatype of the target variable and convert it to binary.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### As we did before, split the dataset into predictors `ex_X` and target `ex_y`.\n",
    "##### Save target variable `y` as an np array to `ex_y`.\n",
    "##### Save the rest of the variables to `ex_X`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Split our data `ex_X` and `ex_y` into training and test sets. Split 70% into the training set and remaining 30% into the test set.\n",
    "##### Save them as `ex_X_train`, `ex_X_test`, `ex_y_train` and `ex_y_test` respectively.\n",
    "##### Make sure to set the seed to 2 so you can replicate the results.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Instantiate the logistic regression model and save it to `ex_logistic_regression_model`. Print it.\n",
    "##### Fit the model with our training sets `ex_X_train` and `ex_y_train`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Now use the trained model to predict on our test set `ex_X_test`. Save as `ex_predicted_values`.\n",
    "##### Print the vector of predictions obtained.\n",
    "##### Create a confusion matrix using the `metrics.confusion_matrix()` function.\n",
    "##### Save as `ex_conf_matrix` and print.\n",
    "##### Calculate the accuracy of our model by comparing our predicted values against our test set `ex_y_test`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "\n",
    "##### Load the pickled dataset `model_final_ex.sav` which we saved earlier.\n",
    "\n",
    "##### Add the accuracy score `ex_test_accuracy` calculated above with the model name as `logistic_withdummies` to the dataframe `ex_model_final` which we created earlier and view the output.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Create a list named `target_names` with the class names as `no` and `yes`.\n",
    "##### Create a report `ex_class_report` using our test values `ex_y_test` and predicted values `ex_predicted_values` with the following columns:\n",
    "- precision\n",
    "- recall\n",
    "- f1-score\n",
    "- target_names\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8\n",
    "##### Get the probabilities of predicted values `ex_X_test` and save as `ex_test_probabilities`.\n",
    "##### Then calculate the probabilities of test predictions named `ex_test_predictions`  only. \n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9\n",
    "##### Derive the `fpr`, `tpr`, and the `threshold` using our test set and predictions.\n",
    "##### Then calculate the `auc` using the derived `fpr` and `tpr`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10\n",
    "##### Plot and ROC curve plot using the values derived above.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Create regularization penalty space named `penalty` and regularization constant space `C` as in slides.\n",
    "##### Then create the hyperparameter dictionary named `hyperparameters`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Set up the 5-fold cross-validation function named `ex_clf`  with the parameters created above.\n",
    "##### Fit the function with our training set. Save as `ex_best_model`.\n",
    "##### Note: If you encounter a convergence warning, use the below code\n",
    "##### ex_clf = GridSearchCV(linear_model.LogisticRegression(solver='liblinear', max_iter=2500), hyperparameters, cv = 5, verbose = 0,                  iid='deprecated')\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Derive the best penalty and constant parameters. Print them.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Print the vector of predicted values named `ex_best_predicted_values`.\n",
    "##### Also find the accuracy score `ex_best_accuracy_score` and print.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Compute the confusion matrix and classification report as above. Save as `ex_best_confusion_matrix` and `ex_best_class_report` respectively.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Add this accuracy score with the model name as `logistic_tuned` to our `ex_model_final` dataframe.\n",
    "##### Pickle this dataset as `ex_model_final_logistic.sav`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Same as before, compute the test probabilities `ex_best_test_probabilities` and \n",
    "##### test predictions `ex_best_test_predictions`.\n",
    "##### Derive the metrics `fpr`, `tpr`, and `threshold` to plot the ROC curve. Also derive the AUC.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8\n",
    "##### Plot the ROC curve for both models.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
